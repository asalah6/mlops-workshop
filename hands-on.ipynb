{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ From Model to Production with MLflow ‚Äì KI Summer Summit Edition\n",
    "\n",
    "## üéØ Ziel des Workshops\n",
    "- Einfaches Machine-Learning-Modell trainieren.\n",
    "- Trainingsversuche mit **MLflow** tracken.\n",
    "- Bestes Modell in der **MLflow Model Registry** speichern und versionieren.\n",
    "- Modell als Test-API mit **Docker + MLflow** bereitstellen.\n",
    "\n",
    "## ü§î Warum ist das wichtig?\n",
    "- Schwierigkeit ohne MLOps:\n",
    "  - √úberblick √ºber Hyperparameter und Datenvarianten geht verloren.\n",
    "  - Gute Modelle wiederfinden ist m√ºhsam.\n",
    "  - Weitergabe an Kollegen oft chaotisch (`modell_final_v2_wirklich_final.pkl`).\n",
    "- **MLOps** schafft Professionalit√§t und Struktur ‚Äì √§hnlich wie DevOps.\n",
    "\n",
    "## üîß Vorteile von MLflow\n",
    "\n",
    "### 1. Experiment Tracking\n",
    "- Erfasst Parameter, Metriken, Artefakte, Code-Versionen.\n",
    "- Vergleich und Analyse von Experimenten.\n",
    "- Unterst√ºtzt Reproduzierbarkeit und Hyperparameter-Tuning.\n",
    "\n",
    "### 2. Model Packaging (MLflow Models)\n",
    "- Einheitliches Format (`MLmodel`).\n",
    "- Plattform√ºbergreifende Nutzung (Python, R, Docker, REST, Spark).\n",
    "- Standardisierte Modell√ºbergabe.\n",
    "- Kompatibel mit Scikit-learn, TensorFlow, PyTorch u.‚ÄØv.‚ÄØm.\n",
    "\n",
    "### 3. Model Registry\n",
    "- Zentrale Verwaltung und Versionierung von Modellen.\n",
    "- **Stages**: `Staging`, `Production`, `Archived`.\n",
    "- Dokumentation mit **Kommentaren** und **Tags**.\n",
    "- Unterst√ºtzt Review, Freigabe und CI/CD.\n",
    "\n",
    "### 4. Deployment & Reproduzierbarkeit\n",
    "- Deployment auf REST-API, Docker, Azure ML, AWS SageMaker, Kubernetes.\n",
    "- Logging von Umgebung, Datenpfaden und Code-Versionen.\n",
    "- Sicherstellung von Reproduzierbarkeit auch langfristig.\n",
    "\n",
    "## üí° Warum MLflow?\n",
    "- üîÑ Reproduzierbare ML-Prozesse.\n",
    "- üë• Bessere Team-Zusammenarbeit durch zentrale Modellverwaltung.\n",
    "- ‚öôÔ∏è Struktur statt Chaos.\n",
    "- ‚è±Ô∏è Schnelleres Deployment in Produktion.\n",
    "- üìä Mehr Fokus auf Modellqualit√§t statt Dokumentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä 2. Vorbereitung: Notwendige Werkzeuge installieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow scikit-learn pandas matplotlib seaborn openpyxl -q\n",
    "print(\"Pakete installiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Die installierten Werkzeuge laden\")\n",
    "import mlflow\n",
    "import mlflow.sklearn # Speziell f√ºr Scikit-learn Modelle mit MLflow\n",
    "import pandas as pd # F√ºr Tabellen-Daten (wie Excel, aber in Python)\n",
    "import matplotlib.pyplot as plt # Zum Erstellen von Diagrammen\n",
    "import seaborn as sns # Macht Diagramme noch sch√∂ner und einfacher\n",
    "from sklearn.model_selection import train_test_split # Zum Aufteilen unserer Daten\n",
    "from sklearn.ensemble import RandomForestClassifier # Unser KI-Modell f√ºr heute\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay # Zum Bewerten des Modells\n",
    "from sklearn.datasets import load_iris # Ein bekannter Beispieldatensatz\n",
    "import os # Um mit Ordnern und Dateien zu arbeiten\n",
    "import json # Um Daten im JSON-Format zu verarbeiten (wichtig f√ºr APIs)\n",
    "import requests # Um Anfragen an Web-APIs zu senden\n",
    "import sklearn # Um die Version von Scikit-learn zu pr√ºfen\n",
    "\n",
    "# Diese Zeile sorgt daf√ºr, dass Diagramme direkt hier im Notebook angezeigt werden\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîå Verbindung zum gemeinsamen MLflow Tracking Server\n",
    "Wir verwenden einen gemeinsamen MLflow Server. Damit wir eure Experimente auseinanderhalten k√∂nnen, erstellt bitte jeder sein eigenes Experiment mit seinem Namen.\n",
    "\n",
    "**WICHTIG:** √Ñndere `DEIN_NAME_HIER` in der n√§chsten Zelle zu deinem Namen oder einem eindeutigen K√ºrzel (ohne Leerzeichen, am besten nur Buchstaben, Zahlen, Unterstriche)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dein Name oder ein eindeutiges K√ºrzel (z.B. MaxM, AnnaS)\n",
    "# BITTE √ÑNDERN:\n",
    "TEILNEHMER_NAME = \"Ahmad\" # <<< HIER DEINEN NAMEN EINTRAGEN!\n",
    "\n",
    "if TEILNEHMER_NAME == \"DEIN_NAME_HIER\" or TEILNEHMER_NAME == \"\":\n",
    "    print(\"WARNUNG: Bitte setze die Variable TEILNEHMER_NAME auf deinen Namen oder ein K√ºrzel!\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"SprinteinsMlFlow123#\"\n",
    "\n",
    "# Die Adresse unseres gemeinsamen MLflow Servers\n",
    "MLFLOW_TRACKING_SERVER_URI = \"https://mlflow.kaywan.de\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_URI)\n",
    "    print(f\"Verbunden mit MLflow Tracking Server: {mlflow.get_tracking_uri()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Konnte MLflow Tracking URI nicht setzen: {e}.\")\n",
    "\n",
    "# Eindeutiger Experimentname f√ºr dich\n",
    "EXPERIMENT_NAME = f\"Iris_Challenge_{TEILNEHMER_NAME}\"\n",
    "try:\n",
    "    # Versucht, das Experiment zu erstellen oder auszuw√§hlen, falls es schon existiert\n",
    "    current_experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if current_experiment is None: # Experiment existiert nicht, neu erstellen\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Neues MLflow Experiment '{EXPERIMENT_NAME}' (ID: {experiment_id}) erstellt.\")\n",
    "    else: # Experiment existiert bereits\n",
    "        experiment_id = current_experiment.experiment_id\n",
    "        print(f\"Vorhandenes MLflow Experiment '{EXPERIMENT_NAME}' (ID: {experiment_id}) ausgew√§hlt.\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id) # Setze als aktives Experiment\n",
    "    \n",
    "    print(f\"Dein Experiment in der MLflow UI: {MLFLOW_TRACKING_SERVER_URI}/#/experiments/{experiment_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Erstellen/Setzen des Experiments '{EXPERIMENT_NAME}': {e}\")\n",
    "    print(\"Stelle sicher, dass der Server erreichbar ist und dein TEILNEHMER_NAME g√ºltig ist (und nicht leer oder der Platzhalter ist).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üå± 3. Daten laden und verstehen\n",
    "Jedes KI-Modell braucht Daten zum Lernen. Wir verwenden den \"Iris\"-Datensatz. Das ist ein klassischer Datensatz in der KI-Welt, der Merkmale von Schwertlilien (Iris) enth√§lt. Ziel ist es, anhand der Bl√ºtenblatt- und Kelchblattma√üe die Art der Iris vorherzusagen.\n",
    "\n",
    "Zuerst laden wir die Daten und schauen sie uns kurz an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade den Iris-Datensatz. 'as_frame=True' gibt uns eine sch√∂ne Tabelle (DataFrame).\n",
    "iris_data = load_iris(as_frame=True)\n",
    "df_iris = iris_data.frame\n",
    "\n",
    "# Wir f√ºgen eine Spalte hinzu, die den Namen der Iris-Art enth√§lt, statt nur einer Zahl.\n",
    "df_iris['target_name'] = df_iris['target'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "\n",
    "print(\"So sehen die ersten 5 Zeilen unserer Daten aus:\")\n",
    "display(df_iris.head()) # 'display' ist sch√∂ner f√ºr Tabellen im Notebook\n",
    "\n",
    "print(f\"\\nInsgesamt haben wir {df_iris.shape[0]} Datenpunkte (Blumen) und {df_iris.shape[1]} Spalten (Merkmale + Ziel). \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Ein Bild sagt mehr als tausend Zahlen: Daten visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erstelle Pairplot... Das kann einen Moment dauern.\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a pairplot showing relationships between all iris featuresrelationships\n",
    "sns.pairplot(df_iris, hue='target_name', diag_kind='kde', markers=[\"o\", \"s\", \"D\"])\n",
    "plt.suptitle(\"Beziehungen der Merkmale im Iris-Datensatz\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"Man sieht schon: Manche Arten (z.B. Setosa, oft blau in Plots) scheinen sich gut von den anderen unterscheiden zu lassen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de81aa",
   "metadata": {},
   "source": [
    "### Interpretation des Pairplots\n",
    "\n",
    "- **Jede Grafik** zeigt die Beziehung zwischen zwei Merkmalen.\n",
    "- **Diagonale Plots**: Verteilung jedes Merkmals pro Iris-Art.\n",
    "- **Wichtige Beobachtungen**:\n",
    "  - Die drei Iris-Arten (Setosa, Versicolor, Virginica) sind farblich und symbolisch unterschieden.\n",
    "  - *Setosa* ist klar von den anderen Arten getrennt (besonders bei **petal length** und **petal width**).\n",
    "  - *Versicolor* und *Virginica* √ºberlappen teilweise ‚Üí Klassifikation hier schwieriger.\n",
    "  - **Bl√ºtenblattmerkmale (petal)** sind aussagekr√§ftiger als **Kelchblattmerkmale (sepal)**.\n",
    "- **Fazit**: Ein gutes ML-Modell sollte diese Muster erkennen und f√ºr die Klassifikation nutzen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Was soll das Modell lernen? Features (X) und Target (y)\n",
    "Wir m√ºssen dem Modell sagen, welche Spalten die Eingabemerkmale (Features, oft `X` genannt) sind und welche Spalte das ist, was wir vorhersagen wollen (Target, oft `y` genannt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Features sind die Spalten mit den Messwerten der Blumen.\n",
    "X = df_iris[iris_data.feature_names] # iris_data.feature_names enth√§lt die Namen der Merkmalsspalten\n",
    "\n",
    "# Das Target ist die Spalte 'target', die die Art der Blume als Zahl (0, 1 oder 2) enth√§lt.\n",
    "y = df_iris['target']\n",
    "\n",
    "print(\"Das sind unsere Eingabemerkmale (X) mit den zugeh√∂rigen Zielwerten (y):\")\n",
    "\n",
    "# Beispiele f√ºr Setosa (Target 0)\n",
    "print(\"\\n--- Beispiele f√ºr Setosa (Target 0) ---\")\n",
    "setosa_examples = pd.concat([X.iloc[:3], y.iloc[:3].rename(\"target\")], axis=1)\n",
    "display(setosa_examples)\n",
    "\n",
    "# Beispiele f√ºr Versicolor (Target 1)\n",
    "print(\"\\n--- Beispiele f√ºr Versicolor (Target 1) ---\")\n",
    "versicolor_examples = pd.concat([X.iloc[50:53], y.iloc[50:53].rename(\"target\")], axis=1)\n",
    "display(versicolor_examples)\n",
    "\n",
    "# Beispiele f√ºr Virginica (Target 2)\n",
    "print(\"\\n--- Beispiele f√ºr Virginica (Target 2) ---\")\n",
    "virginica_examples = pd.concat([X.iloc[100:103], y.iloc[100:103].rename(\"target\")], axis=1)\n",
    "display(virginica_examples)\n",
    "\n",
    "print(\"\\nUnser Modell wird diese Merkmale nutzen, um die Iris-Art (Target 0, 1 oder 2) vorherzusagen.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† 4. Ein KI-Modell trainieren\n",
    "\n",
    "- **Ziel:** Ein Klassifikationsmodell auf Basis von `RandomForestClassifier` trainieren.\n",
    "- **Warum Random Forest?**  \n",
    "  - Robust und oft sehr performant f√ºr Klassifikationsaufgaben.\n",
    "  - Gut geeignet f√ºr kleine bis mittelgro√üe Datens√§tze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir teilen die Daten: 80% zum Trainieren, 20% zum Testen.\n",
    "# Warum teilen? \n",
    "# Modell soll nicht nur Trainingsdaten auswendig lernen (Vermeidung von **Overfitting**). \n",
    "# Wir brauchen Daten, die das Modell noch nicht gesehen hat (**Testset**), um die echte Vorhersagef√§higkeit zu pr√ºfen.\n",
    "# Aufteilung:\n",
    "# Trainingsset** ‚Üí Modell lernen lassen.  \n",
    "# Testset** ‚Üí Modellleistung √ºberpr√ºfen.\n",
    "\n",
    "# 'random_state=42' sorgt daf√ºr, dass die Aufteilung immer gleich ist, wenn wir den Code nochmal ausf√ºhren.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Wir haben {X_train.shape[0]} Datenpunkte zum Trainieren und {X_test.shape[0]} zum Testen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ Das Modell lernt: Training des RandomForestClassifiers\n",
    "Ein Modell hat verschiedene \"Stellschrauben\", sogenannte Hyperparameter. Diese beeinflussen, wie das Modell lernt. Wir w√§hlen hier ein paar typische Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das sind unsere 'Stellschrauben' (Hyperparameter) f√ºr den RandomForest\n",
    "model_hyperparameters = {\n",
    "    \"n_estimators\": 100,     # Wie viele \"B√§ume\" soll unser Wald haben? Weniger f√ºr schnelleres Training.\n",
    "    \"max_depth\": 30,         # Wie tief darf jeder Baum werden?\n",
    "    \"random_state\": 42      # Damit das Modelltraining reproduzierbar ist.\n",
    "}\n",
    "\n",
    "# Wir erstellen unser Modell mit diesen Einstellungen\n",
    "rf_model = RandomForestClassifier(**model_hyperparameters)\n",
    "\n",
    "# Jetzt trainieren wir das Modell mit unseren Trainingsdaten.\n",
    "# Das Modell lernt jetzt Muster in X_train, um y_train vorhersagen zu k√∂nnen.\n",
    "print(\"Modelltraining startet...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Modelltraining abgeschlossen!\")\n",
    "\n",
    "# Nun testen wir, wie gut unser Modell auf den *unbekannten* Testdaten ist.\n",
    "y_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Wir berechnen die Genauigkeit (Accuracy): Wie viel Prozent hat das Modell richtig vorhergesagt?\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "print(f\"\\nGenauigkeit des Modells auf den Testdaten: {accuracy:.2f} (d.h. {accuracy*100:.0f}% richtig!)\")\n",
    "\n",
    "# Die Confusion Matrix zeigt uns genauer, wo das Modell Fehler gemacht hat.\n",
    "print(\"\\nConfusion Matrix (Zeilen: Echte Arten, Spalten: Vorhergesagte Arten):\")\n",
    "cm = confusion_matrix(y_test, y_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Visualisieren der Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris_data.target_names)\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "ax.set_title(\"Leistung des Modells (Confusion Matrix)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Eine perfekte Diagonale von links oben nach rechts unten w√§re ideal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b288e",
   "metadata": {},
   "source": [
    "## **Zwischenfazit & Herausforderung**\n",
    "- Modell erfolgreich trainiert ‚Üí erste gute Ergebnisse.\n",
    "- Aber: √Ñnderungen der Hyperparameter (z.‚ÄØB. `n_estimators=100`, `max_depth=6`) beeinflussen das Ergebnis.\n",
    "- Problem ohne System:\n",
    "  - Manuelle Notizen n√∂tig.\n",
    "  - Ergebnisse schwer vergleichbar.\n",
    "- **L√∂sung:** MLflow f√ºr strukturiertes Experiment-Tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bab53b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/asalah6/mlops-workshop/refs/heads/main/ex_track.png\" width=\"800\" height=\"400\" alt=\"MLflow Tracking Visualization\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"https://raw.githubusercontent.com/asalah6/mlops-workshop/refs/heads/main/ex_track.png\" width=\"800\" height=\"400\" alt=\"MLflow Tracking Visualization\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ **5. MLflow Tracking: Ordnung ins Experimentier-Chaos bringen**\n",
    "- **MLflow-Funktionen:**\n",
    "  - Speichert verwendete **Hyperparameter**.\n",
    "  - Zeichnet erzielte **Metriken** auf (z.‚ÄØB. Accuracy).\n",
    "  - Erm√∂glicht Ablage von **Artefakten**:\n",
    "    - Diagramme (z.‚ÄØB. Confusion Matrix).\n",
    "    - Trainiertes Modell.\n",
    "- **Vorteile:**\n",
    "  - Einfacher Vergleich verschiedener Trainingsl√§ufe.\n",
    "  - Schnelles Wiederfinden guter Modelle.\n",
    "  - Grundlage f√ºr reproduzierbare Experimente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir starten einen \"MLflow Run\". Das ist wie eine einzelne Aufzeichnungssitzung.\n",
    "run_description = f\"RF n_est={model_hyperparameters['n_estimators']}, depth={model_hyperparameters['max_depth']}\"\n",
    "\n",
    "# Der Name, unter dem wir das Modell sp√§ter in der \"Modell-Bibliothek\" (Registry) finden wollen.\n",
    "REGISTERED_MODEL_NAME = f\"IrisRF_{TEILNEHMER_NAME}\"\n",
    "\n",
    "print(f\"Starte MLflow Run f√ºr Experiment '{EXPERIMENT_NAME}'...\")\n",
    "\n",
    "try:\n",
    "    # 'with' sorgt daf√ºr, dass der Run am Ende automatisch geschlossen wird.\n",
    "    with mlflow.start_run(run_name=run_description) as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"MLflow Run gestartet mit ID: {run_id}\")\n",
    "\n",
    "        # 1. Parameter loggen (unsere \"Stellschrauben\")\n",
    "        print(\"Logge Hyperparameter...\")\n",
    "        mlflow.log_params(model_hyperparameters)\n",
    "        \n",
    "        mlflow.log_param(\"daten_aufteilung\", f\"{X_train.shape[0]}/{X_test.shape[0]} train/test\")\n",
    "        mlflow.log_param(\"dataset_size\", len(df_iris))\n",
    "        mlflow.log_param(\"features_used\", \", \".join(X.columns.tolist()))\n",
    "\n",
    "        # 2. Metriken loggen (unsere Ergebnisse)\n",
    "        print(\"Logge Metriken...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # 3. Artefakte loggen (z.B. Diagramme)\n",
    "        print(\"Logge Confusion Matrix als Bild...\")\n",
    "        fig_cm, ax_cm = plt.subplots()\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris_data.target_names)\n",
    "        cm_display.plot(ax=ax_cm, cmap=plt.cm.Greens)\n",
    "        ax_cm.set_title(\"Confusion Matrix (geloggt mit MLflow)\")\n",
    "        # Speichern und loggen des Bildes\n",
    "        mlflow.log_figure(fig_cm, \"evaluation_plots/confusion_matrix.png\")\n",
    "        plt.close(fig_cm) # Schlie√üen, damit es nicht doppelt angezeigt wird\n",
    "\n",
    "        # 4. Das Modell selbst loggen UND in der Registry registrieren\n",
    "        print(f\"Logge das trainierte Modell und registriere es als '{REGISTERED_MODEL_NAME}'...\")\n",
    "        \n",
    "        # 'input_example' und 'signature' helfen MLflow zu verstehen, welche Art von Daten das Modell erwartet und liefert.\n",
    "        # Das ist n√ºtzlich f√ºr das sp√§tere Bereitstellen des Modells als API.\n",
    "        input_example = X_train.head(3) # Ein kleines Beispiel der Eingabedaten\n",
    "        signature = mlflow.models.infer_signature(X_train, y_predictions) # MLflow versucht, das Format selbst zu erkennen\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=rf_model, # Das trainierte Modellobjekt\n",
    "            artifact_path=\"rf_iris_model_files\", # Ordnername innerhalb des Runs f√ºr die Modelldateien\n",
    "            registered_model_name=REGISTERED_MODEL_NAME, # Name f√ºr die Model Registry\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "        print(\"Modell erfolgreich geloggt und registriert!\")\n",
    "\n",
    "    print(\"\\nMLflow Run abgeschlossen.\")\n",
    "    print(f\"Schau dir diesen Run in der MLflow UI an! (Experiment: '{EXPERIMENT_NAME}', Run ID: {run_id})\")\n",
    "    # print(f\"Link zum Run (falls UI erreichbar): {mlflow.get_tracking_uri().replace('file:', '')}/#/experiments/{mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id}/runs/{run_id}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist im MLflow Run aufgetreten: {e}\")\n",
    "    print(\"Stelle sicher, dass der MLflow Tracking Server (oder der lokale Pfad) korrekt eingerichtet ist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53755a",
   "metadata": {},
   "source": [
    "## üìÅ 6. MLflow Model Registry ‚Äì Zentrale Modellverwaltung\n",
    "\n",
    "### **Was ist die Model Registry?**\n",
    "- Zentraler Ort f√ºr gespeicherte **beste Modelle**.\n",
    "- **Versionierung** jeder Modellvariante.\n",
    "- **Stages** f√ºr unterschiedliche Zust√§nde:\n",
    "  - `None` / `Development` ‚Üí In Entwicklung\n",
    "  - `Staging` ‚Üí Zum Testen\n",
    "  - `Production` ‚Üí Produktiv eingesetzt\n",
    "  - `Archived` ‚Üí Veraltet\n",
    "\n",
    "---\n",
    "\n",
    "### **Warum ist das wichtig?**\n",
    "| Vorteil              | Nutzen f√ºr MLOps                             |\n",
    "|----------------------|----------------------------------------------|\n",
    "| ü§ù Zusammenarbeit     | Gemeinsamer Zugriff f√ºr Teams               |\n",
    "| üîÅ Reproduzierbarkeit | Exakte Versionen f√ºr Analysen & Deployments |\n",
    "| üöÄ Deployment         | Klare Prozesse f√ºr √úbergabe & Freigabe      |\n",
    "| üßæ Governance         | Audit-Trail und Kontrolle produktiver Modelle |\n",
    "\n",
    "---\n",
    "\n",
    "### **Kernfunktionen**\n",
    "1. **Versionierung**\n",
    "   - Jede Registrierung eines Modells erzeugt eine neue Version.\n",
    "   - Nachvollziehbarkeit bei Feintuning oder Datenupdates.\n",
    "2. **Stage Management**\n",
    "   - Definierte √úberg√§nge: Development ‚Üí Staging ‚Üí Production ‚Üí Archived.\n",
    "   - Unterst√ºtzt Review- und Deployment-Workflows.\n",
    "3. **Annotation & Dokumentation**\n",
    "   - Kommentare, Metadaten und Beschreibungen hinzuf√ºgen.\n",
    "   - Erm√∂glicht klare Nachvollziehbarkeit und Governance.\n",
    "4. **Zentrale Modellbibliothek**\n",
    "   - Alle Modelle an einem Ort auffindbar und dokumentiert.\n",
    "   - F√∂rdert Teamarbeit und Wiederverwendbarkeit.\n",
    "\n",
    "---\n",
    "\n",
    "### **Manuelle Registrierung (MLflow UI)**\n",
    "1. **Besten Run ausw√§hlen** (nach Accuracy sortieren).\n",
    "2. In den Run-Details ‚Üí **Artifacts ‚Üí Modellordner** (mit `MLmodel`).\n",
    "3. **Register Model** anklicken.\n",
    "4. **Neues Modell** erstellen (`IrisRF_DEIN_NAME`) oder bestehendes Modell ausw√§hlen.\n",
    "5. **Description** hinzuf√ºgen ‚Üí **Register** klicken.\n",
    "6. Unter **\"Models\"** ‚Üí Modell ausw√§hlen ‚Üí Version ansehen.\n",
    "7. **Stage √§ndern** (z.‚ÄØB. zu `Staging` oder `Production`).\n",
    "\n",
    "---\n",
    "\n",
    "**Ergebnis:**  \n",
    "‚Üí Dein bestes Modell ist versioniert, dokumentiert und bereit f√ºr den Einsatz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üåê 7. Das Modell bereitstellen: Von der Datei zur API\n",
    "Ein trainiertes Modell ist sch√∂n, aber meistens wollen wir es auch nutzen k√∂nnen, z.B. in einer App oder auf einer Webseite. Daf√ºr stellen wir es oft als eine Art \"Web-Service\" (API) bereit. Man schickt Daten an die API, und sie schickt eine Vorhersage zur√ºck.\n",
    "\n",
    "MLflow bietet Werkzeuge, um das relativ einfach zu machen.\n",
    "\n",
    "**WICHTIG:** Die folgenden Befehle sind f√ºr die **Kommandozeile (Terminal)** gedacht, nicht direkt f√ºr dieses Notebook. Du m√ºsstest sie auf deinem Computer ausf√ºhren, wo MLflow und Docker (f√ºr Option 2) installiert sind.\n",
    "\n",
    "### 7.1 Schneller Test: Modell lokal als API starten mit `mlflow models serve`\n",
    "Dieser Befehl startet einen einfachen Webserver, der unser Modell √ºber eine API ansprechbar macht. Perfekt f√ºr schnelle Tests.\n",
    "\n",
    "**Beispiel-Kommando (im Terminal ausf√ºhren):**\n",
    "```bash\n",
    "# Zuerst: Sag dem Terminal, wo dein MLflow Server/Logbuch ist.\n",
    "export MLFLOW_TRACKING_URI=\"https://mlflow.kaywan.de\"\n",
    "export MLFLOW_TRACKING_USERNAME=\"mlflow\"\n",
    "export MLFLOW_TRACKING_PASSWORD=\"SprinteinsMlFlow123#\"\n",
    "\n",
    "# Starte den Server f√ºr Version 1 unseres Modells auf Port 5001\n",
    "export MODEL_NAME=\"IrisRF_Ahmad\"\n",
    "mlflow models serve -m \"models:/${MODEL_NAME}/1\" -p 5001 --env-manager local\n",
    "#!nohup mlflow models serve -m \"models:/${MODEL_NAME}/1\" -p 5001 --env-manager local > mlflow.log 2>&1 &\n",
    "#!ps aux | grep mlflow\n",
    "#!kill 12345\n",
    "\n",
    "# Alternativ, wenn du das Modell in Stage \"Production\" geschoben hast:\n",
    "# mlflow models serve -m \"models:/Irisblumen_Klassifikator_RF/Production\" -p 5001 --env-manager local\n",
    "```\n",
    "-   `-m \"models:/Modellname/VersionOderStage\"`: Sagt MLflow, welches Modell es laden soll.\n",
    "-   `-p 5001`: Der Netzwerk-Port, unter dem die API erreichbar ist.\n",
    "-   `--env-manager local`: Nutzt deine lokale Python-Umgebung (einfacher f√ºr Demos).\n",
    "\n",
    "### 7.2 F√ºr die \"echte Welt\": Docker-Container erstellen mit `mlflow models build-docker`\n",
    "F√ºr eine robustere Bereitstellung packt man das Modell und alles, was es braucht, in einen **Docker-Container**, die √ºberall gleich l√§uft.\n",
    "\n",
    "**Beispiel-Kommando (im Terminal ausf√ºhren, Docker muss installiert sein):**\n",
    "```bash\n",
    "\n",
    "# Docker-Image f√ºr unser Modell erstellen (Name: iris-api-service)\n",
    "mlflow models build-docker -m \"models:/Irisblumen_Klassifikator_RF/1\" -n \"iris-api-service\" --env-manager local\n",
    "\n",
    "# Den erstellten Container starten (Port 5001 auf deinem PC leitet zu Port 8080 im Container)\n",
    "# docker run -p 5001:8080 iris-api-service\n",
    "```\n",
    "Dieser Docker-Container k√∂nnte dann z.B. in der Cloud oder auf eigenen Servern betrieben werden.\n",
    "\n",
    "### 7.3 Die API testen: Eine Anfrage senden\n",
    "Wenn dein Modell-Server l√§uft (entweder mit `mlflow models serve` oder via Docker), k√∂nnen wir ihm jetzt Daten schicken und eine Vorhersage bekommen. Das machen wir hier im Notebook mit der `requests` Bibliothek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir nehmen eine Beispiel-Blume aus unseren Testdaten\n",
    "if 'X_test' in locals() and not X_test.empty:\n",
    "    sample_flower_features = X_test.iloc[[0]] # Die erste Blume aus dem Testset\n",
    "    print(\"Diese Blumendaten schicken wir an die API:\")\n",
    "    display(sample_flower_features)\n",
    "\n",
    "    # Die API erwartet die Daten in einem bestimmten JSON-Format.\n",
    "    # 'dataframe_split' ist ein g√§ngiges Format.\n",
    "    payload = {\n",
    "        \"dataframe_split\": {\n",
    "            \"columns\": sample_flower_features.columns.tolist(),\n",
    "            \"data\": sample_flower_features.values.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Die Adresse unserer API (Port 5001, wie oben im Terminal-Befehl festgelegt)\n",
    "    api_url = \"http://localhost:5001/invocations\"\n",
    "\n",
    "    print(f\"\\nSende Anfrage an: {api_url}\")\n",
    "    print(\"Mit diesen Daten (JSON-Format):\\n\", json.dumps(payload, indent=2))\n",
    "\n",
    "    try:\n",
    "        # Wir senden die Daten an die API und warten auf die Antwort\n",
    "        response = requests.post(api_url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "        response.raise_for_status() # L√∂st einen Fehler aus, wenn die API ein Problem meldet (z.B. Fehler 400 oder 500)\n",
    "        \n",
    "        predictions_json = response.json()\n",
    "        print(\"\\nAntwort von der API (Status {}):\".format(response.status_code))\n",
    "        print(json.dumps(predictions_json, indent=2))\n",
    "        \n",
    "        # Die Vorhersage ist meistens unter dem Schl√ºssel 'predictions'\n",
    "        if 'predictions' in predictions_json and len(predictions_json['predictions']) > 0:\n",
    "            predicted_index = predictions_json['predictions'][0]\n",
    "            # Umwandlung des Index (0, 1, 2) in den Namen der Iris-Art\n",
    "            predicted_species_name = iris_data.target_names[int(predicted_index)]\n",
    "            print(f\"\\nDas Modell sagt voraus: Es ist eine Iris '{predicted_species_name}' (Index {predicted_index}).\")\n",
    "        else:\n",
    "            print(\"\\nKonnte die Vorhersage nicht aus der Antwort lesen.\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"\\nFEHLER: Konnte keine Verbindung zu {api_url} herstellen.\")\n",
    "        print(\"Hast du den 'mlflow models serve' oder 'docker run' Befehl in einem separaten Terminal gestartet?\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"\\nHTTP FEHLER von der API: {e}\")\n",
    "        print(\"Antwort der API:\", e.response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nEin anderer Fehler ist aufgetreten: {e}\")\n",
    "else:\n",
    "    print(\"Testdaten (X_test) nicht gefunden. Bitte f√ºhre die Zellen oben aus, um sie zu erstellen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca962a4b",
   "metadata": {},
   "source": [
    "## üîÑ 8. Von manuellen Schritten zur MLOps-Pipeline\n",
    "\n",
    "Die Schritte, die wir in diesem Workshop durchgef√ºhrt haben, k√∂nnen in einer professionellen Umgebung automatisiert werden. Eine strukturierte MLOps-Pipeline hilft dabei, den Prozess reproduzierbar und skalierbar zu machen.\n",
    "\n",
    "### Vorteile einer MLOps-Pipeline:\n",
    "- **Reproduzierbarkeit**: Konsistente Ausf√ºhrung durch Automatisierung\n",
    "- **Konfigurierbarkeit**: Parameter zentral verwalten (√§hnlich zu DVC)\n",
    "- **Skalierbarkeit**: Einfache Anwendung auf gr√∂√üere Datens√§tze\n",
    "- **Versionierung**: Automatisches Tracking aller Artefakte und Parameter\n",
    "\n",
    "### Beispiel einer einfachen Pipeline-Struktur:\n",
    "\n",
    "```python\n",
    "stages:\n",
    "  load_data:\n",
    "    cmd: python src/load_data.py\n",
    "    deps:\n",
    "      - src/load_data.py\n",
    "    outs:\n",
    "      - data/iris.csv\n",
    "\n",
    "  train_model:\n",
    "    cmd: python src/train_model.py\n",
    "    deps:\n",
    "      - src/train_model.py\n",
    "      - data/iris.csv\n",
    "      - params.yaml\n",
    "    outs:\n",
    "      - model.pkl\n",
    "      - data/X_test.csv\n",
    "      - data/y_test.csv\n",
    "\n",
    "  evaluate:\n",
    "    cmd: python src/evaluate.py\n",
    "    deps:\n",
    "      - src/evaluate.py\n",
    "      - model.pkl\n",
    "      - data/X_test.csv\n",
    "      - data/y_test.csv\n",
    "    metrics:\n",
    "      - metrics.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8828a973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/asalah6/mlops-workshop/refs/heads/main/dvs_pipeline.png\" width=\"800\" height=\"400\" alt=\"MLflow Tracking Visualization\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"https://raw.githubusercontent.com/asalah6/mlops-workshop/refs/heads/main/dvs_pipeline.png\" width=\"800\" height=\"400\" alt=\"MLflow Tracking Visualization\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Geschafft! Dein erster vollst√§ndiger MLOps-Durchlauf\n",
    "\n",
    "### **Was wurde erreicht?**\n",
    "1. **Modelltraining**\n",
    "   - Ein KI-Modell erfolgreich trainiert.\n",
    "2. **MLflow Tracking**\n",
    "   - Parameter, Metriken und Artefakte (z.‚ÄØB. Confusion Matrix) geloggt.\n",
    "   - Vergleichbare und reproduzierbare Experimente erstellt.\n",
    "3. **MLflow Model Registry**\n",
    "   - Modell versioniert und Stages zugewiesen.\n",
    "   - Zentrale Ablage und Vorbereitung f√ºr Produktion.\n",
    "4. **Deployment-Konzepte**\n",
    "   - Grundprinzipien f√ºr:\n",
    "     - `mlflow models serve` (lokaler Server)\n",
    "     - Bereitstellung via **Docker**.\n",
    "   - Grundlagen des produktnahen Deployments verstanden.\n",
    "5. **Predictions via REST API**\n",
    "   - Vorhersagen mit `curl` oder `requests` abgerufen.\n",
    "   - Input/Output-Formate von MLflow-APIs kennengelernt.\n",
    "\n",
    "---\n",
    "\n",
    "### **Warum ist das wichtig?**\n",
    "- Nachvollziehbarer und reproduzierbarer ML-Workflow.\n",
    "- Teamfreundlich und skalierbar.\n",
    "- Bereit f√ºr professionelle MLOps-Pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4761b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Wie geht‚Äôs weiter? ‚Äì Deine **Next Steps**\n",
    "\n",
    "> Dieser Workshop war ein Einstieg ‚Äì jetzt kannst du tiefer einsteigen und praxisrelevante Erweiterungen ausprobieren:\n",
    "\n",
    "### üñ•Ô∏è 1. **MLflow UI erkunden**\n",
    "  - Starte die UI lokal (`mlflow ui`) oder auf einem Server.\n",
    "  - Schau dir Runs, Artefakte und die Registry im Detail an.\n",
    "\n",
    "### ‚òÅÔ∏è 2. **Deployment auf Cloud-Plattformen**\n",
    "- MLflow l√§sst sich mit Cloud-Diensten kombinieren:\n",
    "  - AWS SageMaker\n",
    "  - Azure ML\n",
    "  - Google Cloud AI Platform\n",
    "\n",
    "### üß™ 3. **Andere Modelle und Use Cases**\n",
    "- Nutze MLflow f√ºr andere Algorithmen, Frameworks und Datens√§tze.\n",
    "- Teste Tracking und Registry mit NLP, Zeitreihen, Deep Learning usw.\n",
    "\n",
    "### üê≥ 4. **Docker-Deployment real umsetzen**\n",
    "- Erstelle ein Docker-Image deines Modells und teste lokal oder in der Cloud.\n",
    "- Schicke REST-Requests f√ºr echte Vorhersagen.\n",
    "\n",
    "### üîÅ 5. **CI/CD f√ºr ML aufbauen**\n",
    "- Automatisiere Trainings-, Test-, Registrierungs- und Deploymentprozesse:\n",
    "  - z.‚ÄØB. mit GitHub Actions, GitLab CI, Jenkins, Argo Workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üôå Danke!\n",
    "\n",
    "Vielen Dank f√ºr deine Teilnahme am Workshop!  \n",
    "Du hast die Grundlagen gelegt f√ºr strukturiertes, nachhaltiges und teamf√§higes Machine Learning ‚Äì also **echtes MLOps**.\n",
    "\n",
    "> Bleib neugierig, probiere Dinge aus und denk daran:  \n",
    "> Ein gutes Modell ist nichts ohne ein gutes Deployment! üòâ\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
