{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ From Model to Production with MLflow ‚Äì KI Summer Summit Edition üöÄ\n",
    "\n",
    "Herzlich willkommen zu unserem Hands-on MLOps Workshop!\n",
    "\n",
    "Heute schauen wir uns an, wie wir ein einfaches Machine-Learning-Modell trainieren und es so vorbereiten, dass es in einer echten Anwendung genutzt werden k√∂nnte. Dabei spielt **MLflow** eine zentrale Rolle, um uns das Leben leichter zu machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Was erwartet uns heute?\n",
    "\n",
    "### üìå Unser Ziel:\n",
    "Am Ende dieses Workshops wirst du praktisch erlebt haben, wie man:\n",
    "1.  Ein einfaches KI-Modell trainiert.\n",
    "2.  Mit **MLflow** den √úberblick √ºber verschiedene Trainingsversuche beh√§lt (Tracking).\n",
    "3.  Ein gutes Modell in der **MLflow Model Registry** speichert und versioniert.\n",
    "4.  Dieses Modell als Test-API bereitstellt (Deployment mit **Docker + MLflow**).\n",
    "\n",
    "### ü§î Warum ist das wichtig? Die Herausforderung ohne MLOps:\n",
    "Stell dir vor, du trainierst ein KI-Modell. Du probierst verschiedene Einstellungen (sog. Hyperparameter) aus, vielleicht auch verschiedene Datenaufbereitungen. \n",
    "-   *Wie merkst du dir, welche Einstellungen zum besten Ergebnis gef√ºhrt haben?*\n",
    "-   *Wie findest du ein √§lteres, gutes Modell wieder, wenn du es sp√§ter brauchst?*\n",
    "-   *Wie gibst du dein Modell an Kollegen weiter, damit sie es testen oder in ein Produkt einbauen k√∂nnen?*\n",
    "\n",
    "Ohne Werkzeuge wie MLflow wird das schnell un√ºbersichtlich und fehleranf√§llig. Manuelle Notizen, unz√§hlige Dateien mit Namen wie `modell_final_v2_wirklich_final.pkl` sind nicht ideal. MLOps (Machine Learning Operations) hilft, diesen Prozess zu professionalisieren ‚Äì √§hnlich wie DevOps in der Softwareentwicklung.\n",
    "\n",
    "\n",
    "Heute konzentrieren wir uns auf diese drei Aspekte, um einen typischen MLOps-Workflow nachzuvollziehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b49d4",
   "metadata": {},
   "source": [
    "## üöÄ Vorteile von MLflow ‚Äì Das Toolkit f√ºr den ML-Lebenszyklus\n",
    "\n",
    "**MLflow** ist eine Open-Source-Plattform zur Verwaltung des gesamten Machine-Learning-Lebenszyklus ‚Äì von der Entwicklung bis zur Produktion. Sie bietet strukturierte Unterst√ºtzung in vier zentralen Bereichen:\n",
    "\n",
    "\n",
    "### üîé 1. Experiment Tracking\n",
    "\n",
    "- Zeichnet Parameter, Metriken, Artefakte und Code-Versionen auf.\n",
    "- Vergleich und Analyse von Experimenten ‚Äì inkl. Visualisierung.\n",
    "- Unterst√ºtzt Reproduzierbarkeit und systematische Optimierung.\n",
    "- Ideal f√ºr exploratives Arbeiten und Hyperparameter-Tuning.\n",
    "\n",
    "\n",
    "### üì¶ 2. Model Packaging (MLflow Models)\n",
    "\n",
    "- Speichert Modelle in einem einheitlichen Format (`MLmodel`).\n",
    "- Erm√∂glicht plattform√ºbergreifende Nutzung: Python, R, Docker, REST, Spark.\n",
    "- Standardisierte Modell√ºbergabe ‚Äì ideal f√ºr Deployment und Tests.\n",
    "- Unterst√ºtzt verschiedene Frameworks: Scikit-learn, TensorFlow, PyTorch u.v.m.\n",
    "\n",
    "\n",
    "### üóÇÔ∏è 3. Model Registry\n",
    "\n",
    "- Zentrale Verwaltung und Versionierung trainierter Modelle.\n",
    "- Unterst√ºtzt **Stages**: `Staging`, `Production`, `Archived`.\n",
    "- Dokumentation via **Kommentare** und **Tags**.\n",
    "- Erleichtert Review-, Freigabe- und √úbergabeprozesse im Team.\n",
    "- Integriert mit CI/CD-Workflows und Deployment-Pipelines.\n",
    "\n",
    "\n",
    "### üöÄ 4. Deployment & Reproduzierbarkeit\n",
    "\n",
    "- Unterst√ºtzung f√ºr Deployment auf:\n",
    "  - REST-API\n",
    "  - Docker-Container\n",
    "  - Azure ML, AWS SageMaker, Kubernetes\n",
    "- Logging von Umgebung, Datenpfaden und Code-Versionen.\n",
    "- Garantiert **Reproduzierbarkeit** ‚Äì auch nach Monaten oder in neuen Umgebungen.\n",
    "\n",
    "\n",
    "## üí° Warum MLflow nutzen?\n",
    "\n",
    "- üîÑ **Reproduzierbare ML-Prozesse** ‚Äì keine verlorenen Experimente.\n",
    "- üë• **Bessere Team-Zusammenarbeit** ‚Äì durch zentrale Modellverwaltung.\n",
    "- ‚öôÔ∏è **Struktur statt Chaos** ‚Äì alles nachvollziehbar dokumentiert.\n",
    "- ‚è±Ô∏è **Schneller in Produktion** ‚Äì klarer √úbergang von Entwicklung zu Betrieb.\n",
    "- üìä **Mehr Fokus auf Modellqualit√§t** ‚Äì weniger manuelle Dokumentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä 2. Vorbereitung: Notwendige Werkzeuge installieren\n",
    "Zuerst installieren wir die Python-Pakete, die wir f√ºr den Workshop brauchen. Keine Sorge, das ist meist eine einmalige Sache pro Projekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir installieren die ben√∂tigten Pakete. \n",
    "# Das '-q' am Ende sorgt daf√ºr, dass nicht so viel Text bei der Installation ausgegeben wird.\n",
    "!pip install mlflow scikit-learn pandas matplotlib seaborn -q\n",
    "print(\"Pakete installiert! Wenn dies das erste Mal ist, starte ggf. den Kernel neu (oben im Men√º unter 'Kernel' -> 'Restart Kernel').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt laden wir die installierten Werkzeuge in unser Notebook, damit wir sie verwenden k√∂nnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn # Speziell f√ºr Scikit-learn Modelle mit MLflow\n",
    "import pandas as pd # F√ºr Tabellen-Daten (wie Excel, aber in Python)\n",
    "import matplotlib.pyplot as plt # Zum Erstellen von Diagrammen\n",
    "import seaborn as sns # Macht Diagramme noch sch√∂ner und einfacher\n",
    "from sklearn.model_selection import train_test_split # Zum Aufteilen unserer Daten\n",
    "from sklearn.ensemble import RandomForestClassifier # Unser KI-Modell f√ºr heute\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay # Zum Bewerten des Modells\n",
    "from sklearn.datasets import load_iris # Ein bekannter Beispieldatensatz\n",
    "import os # Um mit Ordnern und Dateien zu arbeiten\n",
    "import json # Um Daten im JSON-Format zu verarbeiten (wichtig f√ºr APIs)\n",
    "import requests # Um Anfragen an Web-APIs zu senden\n",
    "import sklearn # Um die Version von Scikit-learn zu pr√ºfen\n",
    "\n",
    "# Diese Zeile sorgt daf√ºr, dass Diagramme direkt hier im Notebook angezeigt werden\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"MLflow Version: {mlflow.__version__}\")\n",
    "print(f\"Scikit-learn Version: {sklearn.__version__}\")\n",
    "print(f\"Pandas Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîå Verbindung zum gemeinsamen MLflow Tracking Server\n",
    "Wir verwenden einen gemeinsamen MLflow Server. Damit wir eure Experimente auseinanderhalten k√∂nnen, erstellt bitte jeder sein eigenes Experiment mit seinem Namen.\n",
    "\n",
    "**WICHTIG:** √Ñndere `DEIN_NAME_HIER` in der n√§chsten Zelle zu deinem Namen oder einem eindeutigen K√ºrzel (ohne Leerzeichen, am besten nur Buchstaben, Zahlen, Unterstriche)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dein Name oder ein eindeutiges K√ºrzel (z.B. MaxM, AnnaS)\n",
    "# BITTE √ÑNDERN:\n",
    "TEILNEHMER_NAME = \"AhmadS\" # <<< HIER DEINEN NAMEN EINTRAGEN!\n",
    "\n",
    "if TEILNEHMER_NAME == \"DEIN_NAME_HIER\" or TEILNEHMER_NAME == \"\":\n",
    "    print(\"WARNUNG: Bitte setze die Variable TEILNEHMER_NAME auf deinen Namen oder ein K√ºrzel!\")\n",
    "    print(\"Du kannst die Zelle trotzdem ausf√ºhren, aber dein Experimentname wird 'DEIN_NAME_HIER' enthalten.\")\n",
    "    #raise ValueError(\"Bitte setze die Variable TEILNEHMER_NAME auf deinen Namen oder ein K√ºrzel!\")\n",
    "\n",
    "# Die Adresse unseres gemeinsamen MLflow Servers\n",
    "MLFLOW_TRACKING_SERVER_URI = \"https://06a8-35-236-198-227.ngrok-free.app\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_SERVER_URI)\n",
    "    print(f\"Verbunden mit MLflow Tracking Server: {mlflow.get_tracking_uri()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Konnte MLflow Tracking URI nicht setzen: {e}.\")\n",
    "\n",
    "# Eindeutiger Experimentname f√ºr dich\n",
    "EXPERIMENT_NAME = f\"Iris_Challenge_{TEILNEHMER_NAME}\"\n",
    "try:\n",
    "    # Versucht, das Experiment zu erstellen oder auszuw√§hlen, falls es schon existiert\n",
    "    current_experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if current_experiment is None: # Experiment existiert nicht, neu erstellen\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Neues MLflow Experiment '{EXPERIMENT_NAME}' (ID: {experiment_id}) erstellt.\")\n",
    "    else: # Experiment existiert bereits\n",
    "        experiment_id = current_experiment.experiment_id\n",
    "        print(f\"Vorhandenes MLflow Experiment '{EXPERIMENT_NAME}' (ID: {experiment_id}) ausgew√§hlt.\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id) # Setze als aktives Experiment\n",
    "    \n",
    "    print(f\"Dein Experiment in der MLflow UI: {MLFLOW_TRACKING_SERVER_URI}/#/experiments/{experiment_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Erstellen/Setzen des Experiments '{EXPERIMENT_NAME}': {e}\")\n",
    "    print(\"Stelle sicher, dass der Server erreichbar ist und dein TEILNEHMER_NAME g√ºltig ist (und nicht leer oder der Platzhalter ist).\")\n",
    "\n",
    "# Eindeutiger Modellname f√ºr die Registry\n",
    "REGISTERED_MODEL_NAME_TEMPLATE = f\"IrisRF_{TEILNEHMER_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üå± 3. Daten laden und verstehen\n",
    "Jedes KI-Modell braucht Daten zum Lernen. Wir verwenden den \"Iris\"-Datensatz. Das ist ein klassischer Datensatz in der KI-Welt, der Merkmale von Schwertlilien (Iris) enth√§lt. Ziel ist es, anhand der Bl√ºtenblatt- und Kelchblattma√üe die Art der Iris vorherzusagen.\n",
    "\n",
    "Zuerst laden wir die Daten und schauen sie uns kurz an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade den Iris-Datensatz. 'as_frame=True' gibt uns eine sch√∂ne Tabelle (DataFrame).\n",
    "iris_data = load_iris(as_frame=True)\n",
    "df_iris = iris_data.frame\n",
    "\n",
    "# Wir f√ºgen eine Spalte hinzu, die den Namen der Iris-Art enth√§lt, statt nur einer Zahl.\n",
    "df_iris['target_name'] = df_iris['target'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "\n",
    "print(\"So sehen die ersten 5 Zeilen unserer Daten aus:\")\n",
    "display(df_iris.head()) # 'display' ist sch√∂ner f√ºr Tabellen im Notebook\n",
    "\n",
    "print(f\"\\nInsgesamt haben wir {df_iris.shape[0]} Datenpunkte (Blumen) und {df_iris.shape[1]} Spalten (Merkmale + Ziel). \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Ein Bild sagt mehr als tausend Zahlen: Daten visualisieren\n",
    "Um ein Gef√ºhl f√ºr die Daten zu bekommen, ist es gut, sie zu visualisieren. Ein `pairplot` zeigt uns, wie die verschiedenen Merkmale (z.B. L√§nge und Breite der Bl√ºtenbl√§tter) miteinander zusammenh√§ngen und ob sich die verschiedenen Iris-Arten dadurch unterscheiden lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erstelle Pairplot... Das kann einen Moment dauern.\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "# 'hue' f√§rbt die Punkte nach der Iris-Art ein.\n",
    "# 'diag_kind=kde' zeigt uns die Verteilung jedes einzelnen Merkmals.\n",
    "sns.pairplot(df_iris, hue='target_name', diag_kind='kde', markers=[\"o\", \"s\", \"D\"])\n",
    "plt.suptitle(\"Beziehungen der Merkmale im Iris-Datensatz\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"Man sieht schon: Manche Arten (z.B. Setosa, oft blau in Plots) scheinen sich gut von den anderen unterscheiden zu lassen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Was soll das Modell lernen? Features (X) und Target (y)\n",
    "Wir m√ºssen dem Modell sagen, welche Spalten die Eingabemerkmale (Features, oft `X` genannt) sind und welche Spalte das ist, was wir vorhersagen wollen (Target, oft `y` genannt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Features sind die Spalten mit den Messwerten der Blumen.\n",
    "X = df_iris[iris_data.feature_names] # iris_data.feature_names enth√§lt die Namen der Merkmalsspalten\n",
    "\n",
    "# Das Target ist die Spalte 'target', die die Art der Blume als Zahl (0, 1 oder 2) enth√§lt.\n",
    "y = df_iris['target']\n",
    "\n",
    "print(\"Das sind unsere Eingabemerkmale (X) f√ºr das Modell (erste 5 Zeilen):\")\n",
    "display(X.head())\n",
    "print(\"\\nDas ist unsere Zielvariable (y), die das Modell vorhersagen soll (erste 5 Zeilen):\")\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† 4. Ein KI-Modell trainieren\n",
    "Jetzt wird's spannend: Wir trainieren ein Modell! Wir verwenden einen `RandomForestClassifier`. Das ist ein g√§ngiges und oft recht gutes Modell f√ºr solche Klassifikationsaufgaben.\n",
    "\n",
    "**Wichtiger Schritt: Daten aufteilen!**\n",
    "Wir k√∂nnen nicht alle Daten zum Trainieren verwenden. Wir brauchen einen Teil der Daten, um sp√§ter zu testen, wie gut unser Modell *unbekannte* Daten vorhersagen kann. Sonst lernt das Modell die Trainingsdaten vielleicht nur auswendig, kann aber nichts Neues. Das nennt man √úberanpassung (Overfitting).\n",
    "Wir teilen unsere Daten also in ein Trainingsset (zum Lernen) und ein Testset (zum √úberpr√ºfen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir teilen die Daten: 80% zum Trainieren, 20% zum Testen.\n",
    "# 'random_state=42' sorgt daf√ºr, dass die Aufteilung immer gleich ist, wenn wir den Code nochmal ausf√ºhren.\n",
    "# 'stratify=y' versucht, die Anteile der Iris-Arten in Trainings- und Testset gleich zu halten.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Wir haben {X_train.shape[0]} Datenpunkte zum Trainieren und {X_test.shape[0]} zum Testen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ Das Modell lernt: Training des RandomForestClassifiers\n",
    "Ein Modell hat verschiedene \"Stellschrauben\", sogenannte Hyperparameter. Diese beeinflussen, wie das Modell lernt. Wir w√§hlen hier ein paar typische Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das sind unsere 'Stellschrauben' (Hyperparameter) f√ºr den RandomForest\n",
    "model_hyperparameters = {\n",
    "    \"n_estimators\": 50,     # Wie viele \"B√§ume\" soll unser Wald haben? Weniger f√ºr schnelleres Training.\n",
    "    \"max_depth\": 4,         # Wie tief darf jeder Baum werden?\n",
    "    \"random_state\": 42      # Damit das Modelltraining reproduzierbar ist.\n",
    "}\n",
    "\n",
    "# Wir erstellen unser Modell mit diesen Einstellungen\n",
    "rf_model = RandomForestClassifier(**model_hyperparameters)\n",
    "\n",
    "# Jetzt trainieren wir das Modell mit unseren Trainingsdaten.\n",
    "# Das Modell lernt jetzt Muster in X_train, um y_train vorhersagen zu k√∂nnen.\n",
    "print(\"Modelltraining startet...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Modelltraining abgeschlossen!\")\n",
    "\n",
    "# Nun testen wir, wie gut unser Modell auf den *unbekannten* Testdaten ist.\n",
    "y_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Wir berechnen die Genauigkeit (Accuracy): Wie viel Prozent hat das Modell richtig vorhergesagt?\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "print(f\"\\nGenauigkeit des Modells auf den Testdaten: {accuracy:.2f} (d.h. {accuracy*100:.0f}% richtig!)\")\n",
    "\n",
    "# Die Confusion Matrix zeigt uns genauer, wo das Modell Fehler gemacht hat.\n",
    "print(\"\\nConfusion Matrix (Zeilen: Echte Arten, Spalten: Vorhergesagte Arten):\")\n",
    "cm = confusion_matrix(y_test, y_predictions)\n",
    "print(cm)\n",
    "\n",
    "# Visualisieren der Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris_data.target_names)\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "ax.set_title(\"Leistung des Modells (Confusion Matrix)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Eine perfekte Diagonale von links oben nach rechts unten w√§re ideal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zwischenfazit und Herausforderung:**\n",
    "Okay, wir haben ein Modell trainiert und es scheint ganz gut zu sein! Aber was, wenn wir jetzt `n_estimators` auf 100 √§ndern? Oder `max_depth` auf 6? Wird es besser oder schlechter? \n",
    "Ohne ein System m√ºssten wir uns das alles manuell notieren oder die Ergebnisse m√ºhsam vergleichen. Hier kommt MLflow ins Spiel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ 5. MLflow Tracking: Ordnung ins Experimentier-Chaos bringen\n",
    "Mit MLflow k√∂nnen wir jetzt diesen Trainingslauf protokollieren. Wir sagen MLflow:\n",
    "-   Welche Hyperparameter wir verwendet haben.\n",
    "-   Welche Genauigkeit (Accuracy) wir erreicht haben.\n",
    "-   Wir k√∂nnen sogar Diagramme (wie die Confusion Matrix) und das trainierte Modell selbst speichern.\n",
    "\n",
    "Das ist super praktisch, um sp√§ter verschiedene Versuche zu vergleichen oder ein gutes Modell wiederzufinden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir starten einen \"MLflow Run\". Das ist wie eine einzelne Aufzeichnungssitzung.\n",
    "run_description = \"Erster RF Versuch mit Basis-Parametern\"\n",
    "\n",
    "# Der Name, unter dem wir das Modell sp√§ter in der \"Modell-Bibliothek\" (Registry) finden wollen.\n",
    "REGISTERED_MODEL_NAME = \"Irisblumen_Klassifikator_RF\"\n",
    "\n",
    "print(f\"Starte MLflow Run f√ºr Experiment '{EXPERIMENT_NAME}'...\")\n",
    "\n",
    "try:\n",
    "    # 'with' sorgt daf√ºr, dass der Run am Ende automatisch geschlossen wird.\n",
    "    with mlflow.start_run(run_name=run_description) as run:\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"MLflow Run gestartet mit ID: {run_id}\")\n",
    "\n",
    "        # 1. Parameter loggen (unsere \"Stellschrauben\")\n",
    "        print(\"Logge Hyperparameter...\")\n",
    "        mlflow.log_params(model_hyperparameters)\n",
    "        mlflow.log_param(\"daten_aufteilung\", \"80/20 train/test\")\n",
    "\n",
    "        # 2. Metriken loggen (unsere Ergebnisse)\n",
    "        print(\"Logge Metriken...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # 3. Artefakte loggen (z.B. Diagramme)\n",
    "        print(\"Logge Confusion Matrix als Bild...\")\n",
    "        fig_cm, ax_cm = plt.subplots()\n",
    "        cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris_data.target_names)\n",
    "        cm_display.plot(ax=ax_cm, cmap=plt.cm.Greens)\n",
    "        ax_cm.set_title(\"Confusion Matrix (geloggt mit MLflow)\")\n",
    "        # Speichern und loggen des Bildes\n",
    "        mlflow.log_figure(fig_cm, \"evaluation_plots/confusion_matrix.png\")\n",
    "        plt.close(fig_cm) # Schlie√üen, damit es nicht doppelt angezeigt wird\n",
    "\n",
    "        # 4. Das Modell selbst loggen UND in der Registry registrieren\n",
    "        print(f\"Logge das trainierte Modell und registriere es als '{REGISTERED_MODEL_NAME}'...\")\n",
    "        \n",
    "        # 'input_example' und 'signature' helfen MLflow zu verstehen, welche Art von Daten das Modell erwartet und liefert.\n",
    "        # Das ist n√ºtzlich f√ºr das sp√§tere Bereitstellen des Modells als API.\n",
    "        input_example = X_train.head(3) # Ein kleines Beispiel der Eingabedaten\n",
    "        signature = mlflow.models.infer_signature(X_train, y_predictions) # MLflow versucht, das Format selbst zu erkennen\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=rf_model, # Das trainierte Modellobjekt\n",
    "            artifact_path=\"rf_iris_model_files\", # Ordnername innerhalb des Runs f√ºr die Modelldateien\n",
    "            registered_model_name=REGISTERED_MODEL_NAME, # Name f√ºr die Model Registry\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "        print(\"Modell erfolgreich geloggt und registriert!\")\n",
    "\n",
    "    print(\"\\nMLflow Run abgeschlossen.\")\n",
    "    print(f\"Schau dir diesen Run in der MLflow UI an! (Experiment: '{EXPERIMENT_NAME}', Run ID: {run_id})\")\n",
    "    # print(f\"Link zum Run (falls UI erreichbar): {mlflow.get_tracking_uri().replace('file:', '')}/#/experiments/{mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id}/runs/{run_id}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist im MLflow Run aufgetreten: {e}\")\n",
    "    print(\"Stelle sicher, dass der MLflow Tracking Server (oder der lokale Pfad) korrekt eingerichtet ist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Was ist jetzt passiert?**\n",
    "Wenn du jetzt die MLflow UI √∂ffnest (die Adresse h√§ngt von deiner Einrichtung ab, bei lokalem Tracking musst du evtl. `mlflow ui --backend-store-uri file:./mlruns_workshop_local` in einem Terminal starten), siehst du unter dem Experiment `KI_Summit_Irisblumen_Klassifikation` einen neuen Eintrag. Dort findest du alle Infos: Parameter, Genauigkeit, das Bild der Confusion Matrix und das gespeicherte Modell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÅ 6. MLflow Model Registry: Die Bibliothek f√ºr unsere besten Modelle\n",
    "Stell dir vor, du hast jetzt viele Modelle trainiert und eines davon ist richtig gut. Das m√∂chtest du vielleicht f√ºr eine Produktivanwendung verwenden. Die Model Registry hilft dir dabei, den √úberblick zu behalten.\n",
    "\n",
    "**Was ist die Model Registry?**\n",
    "-   Ein zentraler Ort, um deine besten Modelle zu speichern.\n",
    "-   Jedes Modell kann mehrere **Versionen** haben (z.B. wenn du es mit neuen Daten nachtrainierst).\n",
    "-   Jede Version kann einen **Status (Stage)** haben, z.B.:\n",
    "    -   `None` oder `Development`: Noch in Entwicklung.\n",
    "    -   `Staging`: Bereit zum Testen in einer Testumgebung.\n",
    "    -   `Production`: Freigegeben f√ºr den produktiven Einsatz.\n",
    "    -   `Archived`: Veraltet, wird nicht mehr verwendet.\n",
    "\n",
    "### üí° Warum ist die Model Registry wichtig?\n",
    "| Vorteil              | Nutzen f√ºr MLOps                                        |\n",
    "|----------------------|----------------------------------------------------------|\n",
    "| ü§ù Zusammenarbeit     | Gemeinsamer Zugriff f√ºr Data Scientists & Engineers     |\n",
    "| üîÅ Reproduzierbarkeit | Exakte Versionen f√ºr Analysen und Deployments           |\n",
    "| üöÄ Deployment         | Klare Prozesse f√ºr √úbergabe & Stage-√úberg√§nge           |\n",
    "| üßæ Governance         | Audit-Trail & Kontrolle √ºber produktive Modellversionen |\n",
    "\n",
    "---\n",
    "\n",
    "Da wir oben `registered_model_name` beim `log_model` angegeben haben, wurde unser Modell `Irisblumen_Klassifikator_RF` automatisch in der Registry angelegt (Version 1, Stage `None`).\n",
    "\n",
    "**N√§chster Schritt (manuell in der MLflow UI):**\n",
    "1.  √ñffne die MLflow UI.\n",
    "2.  Gehe zum Reiter \"Models\".\n",
    "3.  Klicke auf dein Modell `Irisblumen_Klassifikator_RF`.\n",
    "4.  Du siehst Version 1. Klicke darauf.\n",
    "5.  Rechts oben kannst du √ºber \"Stage\" -> \"Transition To\" den Status √§ndern, z.B. auf \"Staging\" oder \"Production\". F√ºr unseren Workshop nehmen wir an, du w√§hlst **\"Production\"** (oder eine andere Stage deiner Wahl).\n",
    "\n",
    "Dies hilft Teams, klar zu definieren, welche Modellversion f√ºr welchen Zweck vorgesehen ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd9009",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è MLflow Model Registry ‚Äì Zentrale Modellverwaltung f√ºr MLOps\n",
    "\n",
    "Die **MLflow Model Registry** ist ein zentrales Repository zur Verwaltung des gesamten Lebenszyklus deiner ML-Modelle. Sie erm√∂glicht:\n",
    "\n",
    "- üìå **Versionierung**\n",
    "- üîÑ **Stage-√úberg√§nge**\n",
    "- üìù **Kommentare & Metadaten**\n",
    "- üèõÔ∏è **Governance & Nachvollziehbarkeit**\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Kernfunktionen\n",
    "\n",
    "#### üìå 1. Modellversionierung\n",
    "- Jede Registrierung eines Modells mit gleichem Namen erzeugt automatisch eine neue Version.\n",
    "- Du kannst alle Trainings-Iterationen nachverfolgen (z.‚ÄØB. bei Feintuning oder Datenupdates).\n",
    "\n",
    "#### üîÑ 2. Stage Management\n",
    "- Modelle lassen sich durch definierte Stufen bewegen:\n",
    "  - `None` / `Development`: Im Aufbau oder experimentell\n",
    "  - `Staging`: Bereit f√ºr Tests\n",
    "  - `Production`: Freigegeben f√ºr Produktion\n",
    "  - `Archived`: Veraltet, nicht mehr aktiv\n",
    "- Die Stage-√úberg√§nge helfen beim Deployment-Workflow und im Review-Prozess.\n",
    "\n",
    "#### üìù 3. Annotation & Dokumentation\n",
    "- F√ºge **Beschreibungen** und **Kommentare** zu Modellen und Versionen hinzu.\n",
    "- Erm√∂glicht Kontext, Review-Nachvollziehbarkeit und Auditability.\n",
    "\n",
    "#### üèõÔ∏è 4. Zentrale Modellbibliothek\n",
    "- Modelle sind an einem Ort auffindbar, versioniert und dokumentiert.\n",
    "- F√∂rdert **Teamarbeit**, **Modell-Wiederverwendung** und **Governance**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53755a",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÅ 6. MLflow Model Registry: Dein bestes Modell f√ºr die Nachwelt\n",
    "\n",
    "Jetzt, wo du (hoffentlich) durch Vergleichen in der MLflow UI deinen besten Run gefunden hast, wollen wir dieses spezifische Modell offiziell in der \"Modell-Bibliothek\" (Model Registry) speichern.\n",
    "\n",
    "**Manuelle Registrierung deines besten Modells √ºber die UI:**\n",
    "\n",
    "1.  **Finde deinen besten Run in der MLflow UI** (in deinem Experiment, sortiert nach Accuracy).\n",
    "2.  Klicke auf diesen besten Run, um die Detailansicht zu √∂ffnen.\n",
    "3.  Unter **\"Artifacts\"** siehst du den Ordner, in dem das Modell gespeichert wurde (standardm√§√üig `model_files` oder der Name, den du bei `artifact_path` in `log_model` angegeben hast).\n",
    "4.  Klicke auf diesen Modellordner. Du solltest jetzt eine Datei namens `MLmodel` und weitere Dateien sehen.\n",
    "5.  Oben rechts auf der Seite dieses Artefakt-Ordners gibt es einen blauen Button **\"Register Model\"**. Klicke darauf.\n",
    "6.  Ein Dialog √∂ffnet sich:\n",
    "    *   **W√§hle \"Create New Model\"** und gib als **Model Name** deinen personalisierten Namen ein: `IrisRF_DEIN_NAME` (z.B. `IrisRF_MaxM`). **Tue dies nur, wenn du diesen Modellnamen zum ERSTEN MAL registrierst.**\n",
    "    *   **ODER:** Wenn du (z.B. im ersten Run) schon ein Modell unter `IrisRF_DEIN_NAME` registriert hast, w√§hle unter **\"Select Model\"** dein existierendes Modell `IrisRF_DEIN_NAME` aus. Dadurch wird eine *neue Version* zu diesem bestehenden registrierten Modell hinzugef√ºgt.\n",
    "    *   Du kannst eine **Description** f√ºr diese Modellversion hinzuf√ºgen (z.B. \"Beste Accuracy mit n_est=X, depth=Y\").\n",
    "    *   Klicke auf **\"Register\"**.\n",
    "7.  Dein Modell ist nun in der Registry! Du kannst es unter dem Reiter **\"Models\"** in der MLflow UI finden.\n",
    "8.  Gehe zu \"Models\", klicke auf dein Modell `IrisRF_DEIN_NAME`.\n",
    "9.  Du siehst jetzt wahrscheinlich **Version 1** (oder eine h√∂here, falls du schon √∂fter registriert hast). Klicke auf die neueste Version (die deines besten Modells).\n",
    "10. Rechts oben kannst du √ºber den Button **\"Stage\"** -> **\"Transition To...\"** den Status dieser Version √§ndern. W√§hle z.B. **\"Staging\"** oder **\"Production\"**. Dies signalisiert, dass dieses Modell bereit f√ºr den n√§chsten Schritt ist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üåê 7. Das Modell bereitstellen: Von der Datei zur API\n",
    "Ein trainiertes Modell ist sch√∂n, aber meistens wollen wir es auch nutzen k√∂nnen, z.B. in einer App oder auf einer Webseite. Daf√ºr stellen wir es oft als eine Art \"Web-Service\" (API) bereit. Man schickt Daten an die API, und sie schickt eine Vorhersage zur√ºck.\n",
    "\n",
    "MLflow bietet Werkzeuge, um das relativ einfach zu machen.\n",
    "\n",
    "**WICHTIG:** Die folgenden Befehle sind f√ºr die **Kommandozeile (Terminal)** gedacht, nicht direkt f√ºr dieses Notebook. Du m√ºsstest sie auf deinem Computer ausf√ºhren, wo MLflow und Docker (f√ºr Option 2) installiert sind.\n",
    "\n",
    "### 7.1 Schneller Test: Modell lokal als API starten mit `mlflow models serve`\n",
    "Dieser Befehl startet einen einfachen Webserver, der unser Modell √ºber eine API ansprechbar macht. Perfekt f√ºr schnelle Tests.\n",
    "\n",
    "**Beispiel-Kommando (im Terminal ausf√ºhren):**\n",
    "```bash\n",
    "# Zuerst: Sag dem Terminal, wo dein MLflow Server/Logbuch ist.\n",
    "export MLFLOW_TRACKING_URI=\"https://06a8-35-236-198-227.ngrok-free.app\" \n",
    "\n",
    "# Starte den Server f√ºr Version 1 unseres Modells auf Port 5001\n",
    "mlflow models serve -m \"models:/Irisblumen_Klassifikator_RF/1\" -p 5001 --env-manager local\n",
    "#!nohup mlflow models serve -m \"models:/Irisblumen_Klassifikator_RF/1\" -p 5001 --env-manager local > mlflow.log 2>&1 &\n",
    "#!ps aux | grep mlflow\n",
    "#!kill 12345\n",
    "\n",
    "# Alternativ, wenn du das Modell in Stage \"Production\" geschoben hast:\n",
    "# mlflow models serve -m \"models:/Irisblumen_Klassifikator_RF/Production\" -p 5001 --env-manager local\n",
    "```\n",
    "-   `-m \"models:/Modellname/VersionOderStage\"`: Sagt MLflow, welches Modell es laden soll.\n",
    "-   `-p 5001`: Der Netzwerk-Port, unter dem die API erreichbar ist.\n",
    "-   `--env-manager local`: Nutzt deine lokale Python-Umgebung (einfacher f√ºr Demos).\n",
    "\n",
    "### 7.2 F√ºr die \"echte Welt\": Docker-Container erstellen mit `mlflow models build-docker`\n",
    "F√ºr eine robustere Bereitstellung packt man das Modell und alles, was es braucht, in einen **Docker-Container**. Das ist wie eine standardisierte Box, die √ºberall gleich l√§uft.\n",
    "\n",
    "**Beispiel-Kommando (im Terminal ausf√ºhren, Docker muss installiert sein):**\n",
    "```bash\n",
    "\n",
    "# Docker-Image f√ºr unser Modell erstellen (Name: iris-api-service)\n",
    "mlflow models build-docker -m \"models:/Irisblumen_Klassifikator_RF/1\" -n \"iris-api-service\" --env-manager local\n",
    "\n",
    "# Den erstellten Container starten (Port 5001 auf deinem PC leitet zu Port 8080 im Container)\n",
    "# docker run -p 5001:8080 iris-api-service\n",
    "```\n",
    "Dieser Docker-Container k√∂nnte dann z.B. in der Cloud oder auf eigenen Servern betrieben werden.\n",
    "\n",
    "### 7.3 Die API testen: Eine Anfrage senden\n",
    "Wenn dein Modell-Server l√§uft (entweder mit `mlflow models serve` oder via Docker), k√∂nnen wir ihm jetzt Daten schicken und eine Vorhersage bekommen. Das machen wir hier im Notebook mit der `requests` Bibliothek.\n",
    "\n",
    "**WICHTIG: Dieser Code funktioniert nur, wenn du parallel einen der obigen Serving-Befehle im Terminal gestartet hast und der Server auf `http://localhost:5001` l√§uft!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir nehmen eine Beispiel-Blume aus unseren Testdaten\n",
    "if 'X_test' in locals() and not X_test.empty:\n",
    "    sample_flower_features = X_test.iloc[[0]] # Die erste Blume aus dem Testset\n",
    "    print(\"Diese Blumendaten schicken wir an die API:\")\n",
    "    display(sample_flower_features)\n",
    "\n",
    "    # Die API erwartet die Daten in einem bestimmten JSON-Format.\n",
    "    # 'dataframe_split' ist ein g√§ngiges Format.\n",
    "    payload = {\n",
    "        \"dataframe_split\": {\n",
    "            \"columns\": sample_flower_features.columns.tolist(),\n",
    "            \"data\": sample_flower_features.values.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Die Adresse unserer API (Port 5001, wie oben im Terminal-Befehl festgelegt)\n",
    "    api_url = \"http://localhost:5001/invocations\"\n",
    "\n",
    "    print(f\"\\nSende Anfrage an: {api_url}\")\n",
    "    print(\"Mit diesen Daten (JSON-Format):\\n\", json.dumps(payload, indent=2))\n",
    "\n",
    "    try:\n",
    "        # Wir senden die Daten an die API und warten auf die Antwort\n",
    "        response = requests.post(api_url, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "        response.raise_for_status() # L√∂st einen Fehler aus, wenn die API ein Problem meldet (z.B. Fehler 400 oder 500)\n",
    "        \n",
    "        predictions_json = response.json()\n",
    "        print(\"\\nAntwort von der API (Status {}):\".format(response.status_code))\n",
    "        print(json.dumps(predictions_json, indent=2))\n",
    "        \n",
    "        # Die Vorhersage ist meistens unter dem Schl√ºssel 'predictions'\n",
    "        if 'predictions' in predictions_json and len(predictions_json['predictions']) > 0:\n",
    "            predicted_index = predictions_json['predictions'][0]\n",
    "            # Umwandlung des Index (0, 1, 2) in den Namen der Iris-Art\n",
    "            predicted_species_name = iris_data.target_names[int(predicted_index)]\n",
    "            print(f\"\\nDas Modell sagt voraus: Es ist eine Iris '{predicted_species_name}' (Index {predicted_index}).\")\n",
    "        else:\n",
    "            print(\"\\nKonnte die Vorhersage nicht aus der Antwort lesen.\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"\\nFEHLER: Konnte keine Verbindung zu {api_url} herstellen.\")\n",
    "        print(\"Hast du den 'mlflow models serve' oder 'docker run' Befehl in einem separaten Terminal gestartet?\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"\\nHTTP FEHLER von der API: {e}\")\n",
    "        print(\"Antwort der API:\", e.response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nEin anderer Fehler ist aufgetreten: {e}\")\n",
    "else:\n",
    "    print(\"Testdaten (X_test) nicht gefunden. Bitte f√ºhre die Zellen oben aus, um sie zu erstellen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÅ 8. (Optional) Bonus ‚Äì Was kommt danach? Monitoring!\n",
    "Wenn ein Modell produktiv l√§uft, ist die Arbeit nicht vorbei! Man muss es im Auge behalten:\n",
    "-   **Bleibt die Leistung gut?** (z.B. Genauigkeit)\n",
    "-   **√Ñndern sich die Daten, die reinkommen?** (sog. Data Drift)\n",
    "-   **Funktioniert die API technisch einwandfrei?** (Latenz, Fehlerraten)\n",
    "\n",
    "Das nennt man **Monitoring**. Daf√ºr gibt es spezielle Werkzeuge (z.B. Evidently AI, Prometheus, Grafana, oder Cloud-Dienste). Das ist aber ein Thema f√ºr einen eigenen Workshop! F√ºr heute ist es wichtig zu wissen, dass dieser Schritt existiert und entscheidend ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Geschafft! Dein erster vollst√§ndiger MLOps-Durchlauf!\n",
    "\n",
    "Herzlichen Gl√ºckwunsch! üéâ  \n",
    "Du hast erfolgreich den Weg von der **Modellentwicklung** bis zur **produktnahen Bereitstellung** mit MLflow durchlaufen. Dabei hast du zentrale Konzepte und Tools der MLOps-Welt praktisch kennengelernt.\n",
    "\n",
    "Super! Du hast heute gesehen und selbst ausprobiert, wie man:\n",
    "1.  Ein KI-Modell trainiert.\n",
    "2.  Mit **MLflow Tracking** den √úberblick √ºber Experimente beh√§lt (Parameter, Metriken, Modelle).\n",
    "3.  Ein Modell in der **MLflow Model Registry** versioniert und f√ºr den Einsatz markiert.\n",
    "4.  Ein Modell prinzipiell als API bereitstellen kann (mit `mlflow models serve` oder Docker).\n",
    "\n",
    "**Warum das alles?** Dieser strukturierte Ansatz hilft enorm, wenn man mit mehreren Modellen, im Team oder √ºber l√§ngere Zeit an KI-Projekten arbeitet. Es macht den Prozess nachvollziehbar, wiederholbar und weniger fehleranf√§llig.\n",
    "\n",
    "### üß† Was haben wir erreicht?\n",
    "1.  üîé **MLflow Tracking**\n",
    "      - Parameter, Metriken und Artefakte wie z.‚ÄØB. Confusion Matrices geloggt.\n",
    "      - Vergleichbare und reproduzierbare Experimente erstellt.\n",
    "2.  üóÇÔ∏è **MLflow Model Registry**\n",
    "      - Gelernt, wie Modelle versioniert und in Stages eingeteilt werden.\n",
    "      - Modelle zentral abgelegt und f√ºr Produktion vorbereitet.\n",
    "3.  üöÄ **Deployment-Konzepte**\n",
    "      - Prinzipielle Bereitstellung via:\n",
    "        - `mlflow models serve` (lokaler Server)\n",
    "        - **Docker Container** f√ºr portable und konsistente Auslieferung\n",
    "      - Die Befehle und Ans√§tze f√ºr reale Umgebungen verstanden (auch wenn im Notebook nicht ausgef√ºhrt).\n",
    "4. üîÑ **Predictions via REST API**\n",
    "      - Gelernt, wie man mit `curl` oder `requests` Vorhersagen von einem bereitgestellten Modell abrufen kann.\n",
    "      - Input/Output-Formate von MLflow-APIs verstanden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4761b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Wie geht‚Äôs weiter? ‚Äì Deine **Next Steps**\n",
    "\n",
    "> Dieser Workshop war ein Einstieg ‚Äì jetzt kannst du tiefer einsteigen und praxisrelevante Erweiterungen ausprobieren:\n",
    "\n",
    "### üñ•Ô∏è 1. **MLflow UI erkunden**\n",
    "  - Starte die UI lokal (`mlflow ui`) oder auf einem Server.\n",
    "  - Schau dir Runs, Artefakte und die Registry im Detail an.\n",
    "\n",
    "### ‚òÅÔ∏è 2. **Deployment auf Cloud-Plattformen**\n",
    "- MLflow l√§sst sich mit Cloud-Diensten kombinieren:\n",
    "  - AWS SageMaker\n",
    "  - Azure ML\n",
    "  - Google Cloud AI Platform\n",
    "\n",
    "### üß™ 3. **Andere Modelle und Use Cases**\n",
    "- Nutze MLflow f√ºr andere Algorithmen, Frameworks und Datens√§tze.\n",
    "- Teste Tracking und Registry mit NLP, Zeitreihen, Deep Learning usw.\n",
    "\n",
    "### üê≥ 4. **Docker-Deployment real umsetzen**\n",
    "- Erstelle ein Docker-Image deines Modells und teste lokal oder in der Cloud.\n",
    "- Schicke REST-Requests f√ºr echte Vorhersagen.\n",
    "\n",
    "### üîÅ 5. **CI/CD f√ºr ML aufbauen**\n",
    "- Automatisiere Trainings-, Test-, Registrierungs- und Deploymentprozesse:\n",
    "  - z.‚ÄØB. mit GitHub Actions, GitLab CI, Jenkins, Argo Workflows\n",
    "\n",
    "---\n",
    "\n",
    "## üôå Danke!\n",
    "\n",
    "Vielen Dank f√ºr deine Teilnahme am Workshop!  \n",
    "Du hast die Grundlagen gelegt f√ºr strukturiertes, nachhaltiges und teamf√§higes Machine Learning ‚Äì also **echtes MLOps**.\n",
    "\n",
    "> Bleib neugierig, probiere Dinge aus und denk daran:  \n",
    "> Ein gutes Modell ist nichts ohne ein gutes Deployment! üòâ\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
